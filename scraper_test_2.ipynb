{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7825e7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install python-dotenv\n",
    "# !{sys.executable} -m pip install google-api-python-client\n",
    "# !{sys.executable} -m pip install iteration-utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daba4ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Link - https://github.com/onlyphantom/youtube_api_python/blob/main/yt_public.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65cf3761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from googleapiclient.discovery import build\n",
    "from iteration_utilities import unique_everseen\n",
    "import csv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "396873f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "426586a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_comments(response_items, csv_output=False):\n",
    "\n",
    "    for res in response_items:\n",
    "\n",
    "        # loop through the replies\n",
    "        if 'replies' in res.keys():\n",
    "            for reply in res['replies']['comments']:\n",
    "                comment = reply['snippet']\n",
    "                comment['commentId'] = reply['id']\n",
    "                comments.append(comment)\n",
    "        else:\n",
    "            comment = {}\n",
    "            comment['snippet'] = res['snippet']['topLevelComment']['snippet']\n",
    "            comment['snippet']['parentId'] = None\n",
    "            comment['snippet']['commentId'] = res['snippet']['topLevelComment']['id']\n",
    "\n",
    "            comments.append(comment['snippet'])\n",
    "\n",
    "    if csv_output:\n",
    "         make_csv(comments)\n",
    "    \n",
    "#     print(f'Finished processing {len(comments)} comments.')\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d73974b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv(comments, channelID=None):\n",
    "    header = comments[0].keys()\n",
    "\n",
    "    if channelID:\n",
    "#         filename = f'comments_{channelID}_{today}.csv'\n",
    "        filename = f'comments.csv'\n",
    "    else:\n",
    "#         filename = f'comments_{today}.csv'\n",
    "        filename = f'comments.csv'\n",
    "\n",
    "    with open(filename, 'a', encoding='utf8', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=header, extrasaction='ignore')\n",
    "        writer.writeheader()\n",
    "        writer.writerows(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23ec1d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c106bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a service object for interacting with the YouTube Data API\n",
    "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY, cache_discovery=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bb12182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment_threads(videoID, to_csv=False):\n",
    "    \n",
    "    comments_list = []\n",
    "    \n",
    "    request = youtube.commentThreads().list(\n",
    "        part='id,replies,snippet',\n",
    "        videoId=videoID,\n",
    "    )\n",
    "    response = request.execute()\n",
    "    comments_list.extend(process_comments(response['items']))\n",
    "\n",
    "    # if there is nextPageToken, then keep calling the API\n",
    "    while response.get('nextPageToken', None):\n",
    "        request = youtube.commentThreads().list(\n",
    "            part='id,replies,snippet',\n",
    "            videoId=videoID,\n",
    "            pageToken=response['nextPageToken']\n",
    "        )\n",
    "        response = request.execute()\n",
    "        comments_list.extend(process_comments(response['items']))\n",
    "\n",
    "    comments_list = list(unique_everseen(comments_list))\n",
    "\n",
    "    print(f\"Finished fetching comments for {videoID}. {len(comments_list)} comments found.\")\n",
    "    \n",
    "    if to_csv:\n",
    "#         make_csv(comments_list, videoID)\n",
    "        make_csv(comments_list)\n",
    "    return comments_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b50d3729",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids = [\n",
    "    'EoArJKQ6t18'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7114b98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing videos:   0%|                                                                         | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "    # get comments\n",
    "#     response = comment_threads(videoID='7Kt6ouYqacQ', to_csv=True)\n",
    "#     print(response)\n",
    "    for video_id in tqdm(video_ids, desc='Processing videos'):\n",
    "        response = comment_threads(videoID=video_id, to_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfc31ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from googleapiclient.discovery import build\n",
    "from iteration_utilities import unique_everseen\n",
    "import csv\n",
    "comments = []\n",
    "def make_csv(comments, channelID=None):\n",
    "    header = comments[0].keys()\n",
    "\n",
    "    if channelID:\n",
    "#         filename = f'comments_{channelID}_{today}.csv'\n",
    "        filename = f'comments.csv'\n",
    "    else:\n",
    "#         filename = f'comments_{today}.csv'\n",
    "        filename = f'comments.csv'\n",
    "\n",
    "    with open(filename, 'w', encoding='utf8', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=header, extrasaction='ignore')\n",
    "        writer.writeheader()\n",
    "        writer.writerows(comments)\n",
    "def comment_threads(videoID, to_csv=False):\n",
    "    \n",
    "    comments_list = []\n",
    "    \n",
    "    request = youtube.commentThreads().list(\n",
    "        part='id,replies,snippet',\n",
    "        videoId=videoID,\n",
    "    )\n",
    "    response = request.execute()\n",
    "    comments_list.extend(process_comments(response['items']))\n",
    "\n",
    "    # if there is nextPageToken, then keep calling the API\n",
    "    while response.get('nextPageToken', None):\n",
    "        request = youtube.commentThreads().list(\n",
    "            part='id,replies,snippet',\n",
    "            videoId=videoID,\n",
    "            pageToken=response['nextPageToken']\n",
    "        )\n",
    "        response = request.execute()\n",
    "        comments_list.extend(process_comments(response['items']))\n",
    "\n",
    "    comments_list = list(unique_everseen(comments_list))\n",
    "\n",
    "    print(f\"Finished fetching comments for {videoID}. {len(comments_list)} comments found.\")\n",
    "    \n",
    "    if to_csv:\n",
    "#         make_csv(comments_list, videoID)\n",
    "        make_csv(comments_list)\n",
    "    return comments_list\n",
    "if __name__ == '__main__':\n",
    "    # get comments\n",
    "    response = comment_threads(videoID='G4EVRUFttG0', to_csv=True)\n",
    "    print(response)\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
