{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7825e7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install python-dotenv\n",
    "# !{sys.executable} -m pip install google-api-python-client\n",
    "# !{sys.executable} -m pip install iteration-utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daba4ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Link - https://github.com/onlyphantom/youtube_api_python/blob/main/yt_public.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65cf3761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from googleapiclient.discovery import build\n",
    "from iteration_utilities import unique_everseen\n",
    "import csv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "396873f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "426586a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_comments(response_items, csv_output=False):\n",
    "\n",
    "    for res in response_items:\n",
    "\n",
    "        # loop through the replies\n",
    "        if 'replies' in res.keys():\n",
    "            for reply in res['replies']['comments']:\n",
    "                comment = reply['snippet']\n",
    "                comment['commentId'] = reply['id']\n",
    "                comments.append(comment)\n",
    "        else:\n",
    "            comment = {}\n",
    "            comment['snippet'] = res['snippet']['topLevelComment']['snippet']\n",
    "            comment['snippet']['parentId'] = None\n",
    "            comment['snippet']['commentId'] = res['snippet']['topLevelComment']['id']\n",
    "\n",
    "            comments.append(comment['snippet'])\n",
    "\n",
    "    if csv_output:\n",
    "         make_csv(comments)\n",
    "    \n",
    "#     print(f'Finished processing {len(comments)} comments.')\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d73974b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv(comments, channelID=None):\n",
    "    header = comments[0].keys()\n",
    "\n",
    "    if channelID:\n",
    "#         filename = f'comments_{channelID}_{today}.csv'\n",
    "        filename = f'comments.csv'\n",
    "    else:\n",
    "#         filename = f'comments_{today}.csv'\n",
    "        filename = f'comments.csv'\n",
    "\n",
    "    with open(filename, 'a', encoding='utf8', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=header, extrasaction='ignore')\n",
    "        writer.writeheader()\n",
    "        writer.writerows(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23ec1d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c106bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a service object for interacting with the YouTube Data API\n",
    "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY, cache_discovery=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bb12182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment_threads(videoID, to_csv=False):\n",
    "    \n",
    "    comments_list = []\n",
    "    \n",
    "    request = youtube.commentThreads().list(\n",
    "        part='id,replies,snippet',\n",
    "        videoId=videoID,\n",
    "    )\n",
    "    response = request.execute()\n",
    "    comments_list.extend(process_comments(response['items']))\n",
    "\n",
    "    # if there is nextPageToken, then keep calling the API\n",
    "    while response.get('nextPageToken', None):\n",
    "        request = youtube.commentThreads().list(\n",
    "            part='id,replies,snippet',\n",
    "            videoId=videoID,\n",
    "            pageToken=response['nextPageToken']\n",
    "        )\n",
    "        response = request.execute()\n",
    "        comments_list.extend(process_comments(response['items']))\n",
    "\n",
    "    comments_list = list(unique_everseen(comments_list))\n",
    "\n",
    "    print(f\"Finished fetching comments for {videoID}. {len(comments_list)} comments found.\")\n",
    "    \n",
    "    if to_csv:\n",
    "#         make_csv(comments_list, videoID)\n",
    "        make_csv(comments_list)\n",
    "    return comments_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b50d3729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_ids = [\n",
    "#     'EoArJKQ6t18'\n",
    "# ]\n",
    "video_ids = [\n",
    "    '-WrRhys0mHU',\n",
    "    's-ZPAcc9i4w',\n",
    "    'deNOEjZtSfI'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7114b98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:   5%|███                                                             | 1/21 [01:11<23:52, 71.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fetching comments for yE5c23LEhZw. 3588 comments found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing videos:  10%|██████                                                         | 2/21 [03:17<32:48, 103.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fetching comments for FMGH8r_Ih5I. 5768 comments found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing videos:  14%|█████████▏                                                      | 3/21 [03:56<22:11, 73.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fetching comments for B2NAMXMHQqU. 6272 comments found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing videos:  19%|████████████▏                                                   | 4/21 [04:30<16:33, 58.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fetching comments for VIqyhPZah7k. 6652 comments found.\n",
      "Finished fetching comments for PSnKTv27104. 6757 comments found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing videos:  24%|███████████████▏                                                | 5/21 [04:42<11:07, 41.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fetching comments for MSy5ZF05PQQ. 11346 comments found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing videos:  29%|█████████████████▍                                           | 6/21 [28:14<2:06:54, 507.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fetching comments for hJdl9E2GRYw. 12613 comments found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing videos:  33%|████████████████████▎                                        | 7/21 [51:39<3:06:50, 800.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fetching comments for 7Jcvd_G8uT4. 12969 comments found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing videos:  38%|███████████████████████▏                                     | 8/21 [57:48<2:23:43, 663.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fetching comments for ihb6GxDy2Z4. 13050 comments found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing videos:  43%|██████████████████████████▏                                  | 9/21 [59:23<1:37:09, 485.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fetching comments for 5fTBWT2aO_E. 13880 comments found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing videos:  48%|███████████████████████████▌                              | 10/21 [1:15:05<1:54:52, 626.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fetching comments for -9TIZROu-fY. 14031 comments found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing videos:  52%|██████████████████████████████▍                           | 11/21 [1:17:27<1:19:42, 478.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fetching comments for 0OWV1FWABDA. 19688 comments found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing videos:  57%|████████████████████████████████▌                        | 12/21 [3:18:06<6:20:13, 2534.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fetching comments for FYoMO1s6jco. 20593 comments found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing videos:  62%|███████████████████████████████████▎                     | 13/21 [3:43:26<4:56:59, 2227.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fetching comments for 6G749ZVOrsk. 20598 comments found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing videos:  67%|██████████████████████████████████████                   | 14/21 [3:44:05<3:02:45, 1566.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fetching comments for kwI1tiiOxXE. 20686 comments found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing videos:  71%|████████████████████████████████████████▋                | 15/21 [3:47:18<1:55:14, 1152.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fetching comments for umabahhE8d4. 20740 comments found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing videos:  76%|████████████████████████████████████████████▏             | 16/21 [3:49:14<1:10:03, 840.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fetching comments for pYJkf5CIviQ. 20767 comments found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing videos:  81%|████████████████████████████████████████████████▌           | 17/21 [3:50:56<41:13, 618.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fetching comments for R98JLQXIwYo. 20858 comments found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing videos:  86%|███████████████████████████████████████████████████▍        | 18/21 [3:56:37<26:45, 535.08s/it]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "    # get comments\n",
    "#     response = comment_threads(videoID='7Kt6ouYqacQ', to_csv=True)\n",
    "#     print(response)\n",
    "    for video_id in tqdm(video_ids, desc='Processing videos'):\n",
    "        response = comment_threads(videoID=video_id, to_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfc31ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from googleapiclient.discovery import build\n",
    "from iteration_utilities import unique_everseen\n",
    "import csv\n",
    "comments = []\n",
    "def make_csv(comments, channelID=None):\n",
    "    header = comments[0].keys()\n",
    "\n",
    "    if channelID:\n",
    "#         filename = f'comments_{channelID}_{today}.csv'\n",
    "        filename = f'comments.csv'\n",
    "    else:\n",
    "#         filename = f'comments_{today}.csv'\n",
    "        filename = f'comments.csv'\n",
    "\n",
    "    with open(filename, 'w', encoding='utf8', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=header, extrasaction='ignore')\n",
    "        writer.writeheader()\n",
    "        writer.writerows(comments)\n",
    "def comment_threads(videoID, to_csv=False):\n",
    "    \n",
    "    comments_list = []\n",
    "    \n",
    "    request = youtube.commentThreads().list(\n",
    "        part='id,replies,snippet',\n",
    "        videoId=videoID,\n",
    "    )\n",
    "    response = request.execute()\n",
    "    comments_list.extend(process_comments(response['items']))\n",
    "\n",
    "    # if there is nextPageToken, then keep calling the API\n",
    "    while response.get('nextPageToken', None):\n",
    "        request = youtube.commentThreads().list(\n",
    "            part='id,replies,snippet',\n",
    "            videoId=videoID,\n",
    "            pageToken=response['nextPageToken']\n",
    "        )\n",
    "        response = request.execute()\n",
    "        comments_list.extend(process_comments(response['items']))\n",
    "\n",
    "    comments_list = list(unique_everseen(comments_list))\n",
    "\n",
    "    print(f\"Finished fetching comments for {videoID}. {len(comments_list)} comments found.\")\n",
    "    \n",
    "    if to_csv:\n",
    "#         make_csv(comments_list, videoID)\n",
    "        make_csv(comments_list)\n",
    "    return comments_list\n",
    "if __name__ == '__main__':\n",
    "    # get comments\n",
    "    response = comment_threads(videoID='G4EVRUFttG0', to_csv=True)\n",
    "    print(response)\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
