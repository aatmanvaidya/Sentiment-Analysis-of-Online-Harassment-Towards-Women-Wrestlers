{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9db05567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install python-dotenv\n",
    "# !{sys.executable} -m pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3fab1621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install iteration_utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2a9b7f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from googleapiclient.discovery import build\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from iteration_utilities import unique_everseen\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c856dfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b7e9e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a service object for interacting with the YouTube Data API\n",
    "youtube = build(\"youtube\", \"v3\", developerKey=api_key, cache_discovery=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "762a9c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "# link = \"https://www.youtube.com/watch?v=36N1Bz7qW0A\"\n",
    "# request = youtube.commentThreads().list(part='id,replies,snippet', videoId=extract_video_id(link))\n",
    "# response = request.execute()\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2d2a2307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_id(url):\n",
    "    video_id = None\n",
    "    if \"youtu.be\" in url:\n",
    "        video_id = url.split(\"/\")[-1]\n",
    "    else:\n",
    "        query_string = url.split(\"?\")[-1]\n",
    "        parameters = query_string.split(\"&\")\n",
    "        for param in parameters:\n",
    "            if param.startswith(\"v=\"):\n",
    "                video_id = param[2:]\n",
    "                break\n",
    "\n",
    "    return video_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1cc1a7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "68d12b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv(comments, channelID=None):\n",
    "    header = comments[0].keys()\n",
    "\n",
    "    if channelID:\n",
    "#         filename = f'comments_{channelID}_{today}.csv'\n",
    "        filename = f'comments.csv'\n",
    "    else:\n",
    "#         filename = f'comments_{today}.csv'\n",
    "        filename = f'comments.csv'\n",
    "\n",
    "    with open(filename, 'a', encoding='utf8', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=header, extrasaction='ignore')\n",
    "        writer.writeheader()\n",
    "        writer.writerows(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "edaf26a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_comments(response_items, csv_output=False):\n",
    "\n",
    "    for res in response_items:\n",
    "\n",
    "        # loop through the replies\n",
    "        if 'replies' in res.keys():\n",
    "            for reply in res['replies']['comments']:\n",
    "                comment = reply['snippet']\n",
    "                comment['commentId'] = reply['id']\n",
    "                comments.append(comment)\n",
    "        else:\n",
    "            comment = {}\n",
    "            comment['snippet'] = res['snippet']['topLevelComment']['snippet']\n",
    "            comment['snippet']['parentId'] = None\n",
    "            comment['snippet']['commentId'] = res['snippet']['topLevelComment']['id']\n",
    "\n",
    "            comments.append(comment['snippet'])\n",
    "\n",
    "    if csv_output:\n",
    "         make_csv(comments)\n",
    "    \n",
    "    print(f'Finished processing {len(comments)} comments.')\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "889124ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment_threads(videoID, to_csv=False):\n",
    "    \n",
    "    comments_list = []\n",
    "    \n",
    "    request = youtube.commentThreads().list(\n",
    "        part='id,replies,snippet',\n",
    "        videoId=videoID,\n",
    "    )\n",
    "    response = request.execute()\n",
    "    comments_list.extend(process_comments(response['items']))\n",
    "\n",
    "    # if there is nextPageToken, then keep calling the API\n",
    "    while response.get('nextPageToken', None):\n",
    "        request = youtube.commentThreads().list(\n",
    "            part='id,replies,snippet',\n",
    "            videoId=videoID,\n",
    "            pageToken=response['nextPageToken']\n",
    "        )\n",
    "        response = request.execute()\n",
    "        comments_list.extend(process_comments(response['items']))\n",
    "\n",
    "    comments_list = list(unique_everseen(comments_list))\n",
    "\n",
    "    print(f\"Finished fetching comments for {videoID}. {len(comments_list)} comments found.\")\n",
    "    \n",
    "    if to_csv:\n",
    "#         make_csv(comments_list, videoID)\n",
    "        make_csv(comments_list)\n",
    "    return comments_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fcad3cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids = [\n",
    "    '36N1Bz7qW0A'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3bc87003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing videos:   0%|                                                                         | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing 23 comments.\n",
      "Finished processing 45 comments.\n",
      "Finished processing 65 comments.\n",
      "Finished processing 85 comments.\n",
      "Finished processing 105 comments.\n",
      "Finished processing 125 comments.\n",
      "Finished processing 148 comments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: 100%|█████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fetching comments for 36N1Bz7qW0A. 148 comments found.\n",
      "CPU times: total: 438 ms\n",
      "Wall time: 1.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "    # get comments\n",
    "#     response = comment_threads(videoID='7Kt6ouYqacQ', to_csv=True)\n",
    "#     print(response)\n",
    "    for video_id in tqdm(video_ids, desc='Processing videos'):\n",
    "        response = comment_threads(videoID=video_id, to_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b5d7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
